"""
æ¨¡å‹è®­ç»ƒè„šæœ¬
ä»userlistæ–‡ä»¶æå–ç‰¹å¾å¹¶è®­ç»ƒæ¨¡å‹
"""

import argparse
import json
import logging
from pathlib import Path
import sys

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from pybotfinder import FeatureExtractor, ModelTrainer

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def main():
    parser = argparse.ArgumentParser(description="è®­ç»ƒæœºå™¨äººæ£€æµ‹æ¨¡å‹")
    parser.add_argument("--profiles-dir", type=str, default="../pybotfinder_prepare/dataset/profiles_dir",
                       help="Profileæ•°æ®ç›®å½•")
    parser.add_argument("--posts-dir", type=str, default="../pybotfinder_prepare/dataset/posts_dir",
                       help="Postsæ•°æ®ç›®å½•")
    parser.add_argument("--userlist-dir", type=str, default="..",
                       help="Userlistæ–‡ä»¶æ‰€åœ¨ç›®å½•")
    parser.add_argument("--features-file", type=str, default="features.json",
                       help="ç‰¹å¾æ–‡ä»¶ä¿å­˜è·¯å¾„")
    parser.add_argument("--model-path", type=str, default="pybotfinder/bot_detection_model.pkl",
                       help="æ¨¡å‹ä¿å­˜è·¯å¾„")
    parser.add_argument("--test-size", type=float, default=0.2,
                       help="æµ‹è¯•é›†æ¯”ä¾‹ï¼ˆé»˜è®¤0.2ï¼‰")
    parser.add_argument("--cv-folds", type=int, default=5,
                       help="äº¤å‰éªŒè¯æŠ˜æ•°ï¼ˆé»˜è®¤5ï¼‰")
    parser.add_argument("--random-state", type=int, default=42,
                       help="éšæœºç§å­ï¼ˆé»˜è®¤42ï¼‰")
    
    args = parser.parse_args()
    
    logger.info("="*60)
    logger.info("å¼€å§‹æ¨¡å‹è®­ç»ƒæµç¨‹")
    logger.info("="*60)
    
    # 1. æå–ç‰¹å¾
    logger.info("\næ­¥éª¤1: æå–ç‰¹å¾...")
    
    # åˆ›å»ºç‰¹å¾æå–å™¨
    extractor = FeatureExtractor(
        profiles_dir=args.profiles_dir,
        posts_dir=args.posts_dir
    )
    
    # æ„å»ºæ–‡ä»¶è·¯å¾„å’Œæ ‡ç­¾æ˜ å°„
    userlist_dir = Path(args.userlist_dir)
    label_mapping = {}
    userlist_files = []
    
    # æ·»åŠ æœºå™¨äººæ–‡ä»¶ï¼ˆæ ‡ç­¾=1ï¼‰
    bot_file = userlist_dir / "bot.txt"
    if bot_file.exists():
        userlist_files.append(str(bot_file))
        label_mapping["bot.txt"] = 1
        logger.info(f"âœ“ æœºå™¨äººæ–‡ä»¶: {bot_file} (æ ‡ç­¾=1)")
    else:
        logger.warning(f"âœ— æ–‡ä»¶ä¸å­˜åœ¨: {bot_file}")
    
    # æ·»åŠ äººç±»æ–‡ä»¶ï¼ˆæ ‡ç­¾=0ï¼‰
    human_files = ["human.txt", "government.txt", "influencer.txt", "media.txt"]
    for human_file in human_files:
        file_path = userlist_dir / human_file
        if file_path.exists():
            userlist_files.append(str(file_path))
            label_mapping[human_file] = 0
            logger.info(f"âœ“ äººç±»æ–‡ä»¶: {file_path} (æ ‡ç­¾=0)")
        else:
            logger.warning(f"âœ— æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
    
    if not userlist_files:
        logger.error("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•userlistæ–‡ä»¶ï¼")
        return
    
    logger.info(f"\nå…± {len(userlist_files)} ä¸ªæ–‡ä»¶")
    logger.info("="*60)
    
    # æå–ç‰¹å¾
    features_list = extractor.extract_features_from_userlists(
        userlist_files,
        label_mapping=label_mapping
    )
    
    logger.info(f"\nç‰¹å¾æå–å®Œæˆï¼å…±æå– {len(features_list)} ä¸ªç”¨æˆ·çš„ç‰¹å¾")
    
    # ç»Ÿè®¡æ ‡ç­¾åˆ†å¸ƒ
    label_counts = {}
    for features in features_list:
        label = features.get('label')
        if label is not None:
            label_counts[label] = label_counts.get(label, 0) + 1
    
    logger.info(f"\næ ‡ç­¾åˆ†å¸ƒ:")
    for label, count in sorted(label_counts.items()):
        label_name = "æœºå™¨äºº" if label == 1 else "äººç±»"
        logger.info(f"  {label_name} (æ ‡ç­¾={label}): {count} ä¸ªç”¨æˆ·")
    
    # ä¿å­˜ç‰¹å¾
    features_path = Path(args.features_file)
    extractor.save_features(features_list, str(features_path))
    logger.info(f"\nâœ… ç‰¹å¾å·²ä¿å­˜åˆ°: {features_path}")
    
    # 2. è®­ç»ƒæ¨¡å‹
    logger.info("\n" + "="*60)
    logger.info("æ­¥éª¤2: è®­ç»ƒæ¨¡å‹...")
    logger.info("="*60)
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = ModelTrainer(
        features_file=str(features_path),
        test_size=args.test_size,
        random_state=args.random_state
    )
    
    # è®­ç»ƒå’Œè¯„ä¼°
    results = trainer.train_and_evaluate(
        save_model=True,
        model_path=args.model_path,
        cv_folds=args.cv_folds
    )
    
    logger.info(f"\nâœ… æ¨¡å‹å·²ä¿å­˜åˆ°: {args.model_path}")
    
    # æ‰“å°æ‘˜è¦
    logger.info("\n" + "="*60)
    logger.info("è®­ç»ƒæ‘˜è¦")
    logger.info("="*60)
    logger.info(f"æœ€ä½³å‚æ•°: {results['cv_results']['best_params']}")
    logger.info(f"äº¤å‰éªŒè¯F1åˆ†æ•°: {results['cv_results']['best_cv_score']:.4f}")
    logger.info(f"æµ‹è¯•é›†å‡†ç¡®ç‡: {results['test_results']['accuracy']:.4f}")
    logger.info(f"æµ‹è¯•é›†F1åˆ†æ•° (å®å¹³å‡): {results['test_results']['f1_score']['macro']:.4f}")
    logger.info(f"æµ‹è¯•é›†F1åˆ†æ•° (åŠ æƒå¹³å‡): {results['test_results']['f1_score']['weighted']:.4f}")
    logger.info("="*60)
    
    logger.info("\nğŸ‰ æ¨¡å‹è®­ç»ƒå®Œæˆï¼")


if __name__ == "__main__":
    main()
